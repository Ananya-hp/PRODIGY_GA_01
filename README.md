ğŸ¯Task1 - Text Generation with GPT-2 
ğŸ”Task Objective 

 Train a model to generate Coherent and contextually relevant text based on a given prompt.A transformer model developed by Open AI Create text that mimics the Style and structure of training data.

 ğŸ”¹ï¸Features
 
 â–ªï¸Uses Hugging Face Transformers to load the GPT-2 model
 
 â–ªï¸Uses Gradio to create simple web UI
 
 â–ªï¸Take input a prompt from User 
 
 â–ªï¸ Generates Coherent, human like text in real time.

 ğŸ›  Technologies Used:
 ğŸ”¸ï¸ Transformers by Hugging Face 
 ğŸ”¸ï¸ Gradio for web interface 
 ğŸ”¸ï¸ Python
 ğŸ”¸ï¸ Google Colab

 ğŸ“· Screenshot of Output

 ![Screenshot_20250627-215838_LinkedIn](https://github.com/user-attachments/assets/e8bb2efa-da51-46db-b363-ddc80721415b)

 â–¶ï¸ How to run

 python GPT2.ipynb 


 

 
