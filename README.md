ğŸ¯Task1- Text Generation with GPT-2 

ğŸ”Task Objective 

 Train a model to generate Coherent and contextually relevant text based on a given prompt.A transformer model developed by Open AI Create text that mimics the Style and structure of training data.

 ğŸ”¹ï¸Features
 
 â–ªï¸Uses Hugging Face Transformers to load the GPT-2 model
 
 â–ªï¸Uses Gradio to create simple web UI
 
 â–ªï¸Take input a prompt from User 
 
 â–ªï¸ Generates Coherent, human like text in real time.

 ğŸ›  Technologies Used:
 
 ğŸ”¸ï¸ Transformers by Hugging Face 
 
 ğŸ”¸ï¸ Gradio for web interface 
 
 ğŸ”¸ï¸ Python
 
 ğŸ”¸ï¸ Google Colab
 

 ğŸ“·Screenshot of code

 ![Screenshot_20250629-205516_LinkedIn](https://github.com/user-attachments/assets/0a22ed19-d1d4-4aac-b007-0aa8fe81c18a)

 ![Screenshot_20250629-205518_LinkedIn](https://github.com/user-attachments/assets/fd88805f-b25a-428c-890e-2a85b6ae8442)

 ![Screenshot_20250629-205521_LinkedIn](https://github.com/user-attachments/assets/48b0c991-dc33-4b42-bae9-3b0a72038bbb)

 Output

 ![Screenshot_20250627-215838_LinkedIn](https://github.com/user-attachments/assets/361b9be1-4ed4-4f51-a8a7-6785286b5463)









 


 

 
